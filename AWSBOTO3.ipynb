{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3=boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4YK9RXA85T6VGBEJ',\n",
       "  'HostId': 'SOW2L3KrvYJ7BxsujrBPUkbKe4z/4ae5bmgoLxaUb23HRVptnozfw5cFL7zUjxE9eUph8H7L0Y8=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'SOW2L3KrvYJ7BxsujrBPUkbKe4z/4ae5bmgoLxaUb23HRVptnozfw5cFL7zUjxE9eUph8H7L0Y8=',\n",
       "   'x-amz-request-id': '4YK9RXA85T6VGBEJ',\n",
       "   'date': 'Sat, 28 Dec 2024 17:41:40 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [],\n",
       " 'Owner': {'DisplayName': 'boreddyprahaladhareddy',\n",
       "  'ID': 'ab93d5351552cae394fbb87b443f96c87747da8fe4bd5dea236ea465aecaf001'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucket(bucket_name):\n",
    "  s3.create_bucket(Bucket=bucket_name)\n",
    "  print('Bucket is created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'sreenu-bucket-1234'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket is created\n"
     ]
    }
   ],
   "source": [
    "create_bucket(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'ZJTVQXKVCZ0SDTJ5',\n",
       "  'HostId': 'QjLc64BXElvII1UDGfdom/s5SmfvkT4iSCLNOQXd/wAOteMiHf+dxij23sQAEhdnxD8ZodpZ+0o=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'QjLc64BXElvII1UDGfdom/s5SmfvkT4iSCLNOQXd/wAOteMiHf+dxij23sQAEhdnxD8ZodpZ+0o=',\n",
       "   'x-amz-request-id': 'ZJTVQXKVCZ0SDTJ5',\n",
       "   'date': 'Sat, 28 Dec 2024 17:46:15 GMT',\n",
       "   'content-type': 'application/xml',\n",
       "   'transfer-encoding': 'chunked',\n",
       "   'server': 'AmazonS3'},\n",
       "  'RetryAttempts': 0},\n",
       " 'Buckets': [{'Name': 'sreenu-bucket-1234',\n",
       "   'CreationDate': datetime.datetime(2024, 12, 28, 17, 46, tzinfo=tzutc())}],\n",
       " 'Owner': {'DisplayName': 'boreddyprahaladhareddy',\n",
       "  'ID': 'ab93d5351552cae394fbb87b443f96c87747da8fe4bd5dea236ea465aecaf001'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3.list_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def upload_file(file_path,object_name=None):\n",
    "  if object_name is None:\n",
    "    object_name=os.path.basename(file_path)\n",
    "  s3.upload_file(file_path,bucket_name,object_name)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_file('creds/Prahalad_ReddyKEY.pem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_objects(bucket_name):\n",
    "  response=s3.list_objects_v2(Bucket=bucket_name)\n",
    "  for obj in response['Contents']:\n",
    "    print(obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Key': 'Prahalad_ReddyKEY.pem', 'LastModified': datetime.datetime(2024, 12, 28, 17, 51, 37, tzinfo=tzutc()), 'ETag': '\"cddc810234be2f62b46a2f6ec7cc4c20\"', 'Size': 1700, 'StorageClass': 'STANDARD'}\n",
      "{'Key': 's3_key/Prahalad_ReddyKEY.pem', 'LastModified': datetime.datetime(2024, 12, 28, 18, 20, 52, tzinfo=tzutc()), 'ETag': '\"cddc810234be2f62b46a2f6ec7cc4c20\"', 'Size': 1700, 'StorageClass': 'STANDARD'}\n",
      "{'Key': 's3_key/pragalad_EC2', 'LastModified': datetime.datetime(2024, 12, 28, 18, 20, 51, tzinfo=tzutc()), 'ETag': '\"1cf688be20e3772e30ef2b43ef75bb17\"', 'Size': 1700, 'StorageClass': 'STANDARD'}\n"
     ]
    }
   ],
   "source": [
    "list_objects(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(object_name,file_path):\n",
    "  if not os.path.exists(os.path.dirname(file_path)):\n",
    "    os.makedirs(os.path.dirname(file_path))\n",
    "  s3.download_file(bucket_name,object_name,file_path)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file('Prahalad_ReddyKEY.pem','data_download/Prahalad_ReddyKEY.pem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_download [] ['Prahalad_ReddyKEY.pem']\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk('data_download'):\n",
    "  print(root,dirs,files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_directory(directory_path,s3_prefix):\n",
    "  for root,dirs,files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "      file_path=os.path.join(root,file).replace('\\\\','/')\n",
    "      real_path=os.path.relpath(file_path,directory_path)\n",
    "      print(real_path)\n",
    "      s3_key=os.path.join(s3_prefix,real_path).replace('\\\\','/')\n",
    "      s3.upload_file(file_path,bucket_name,s3_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\bored\\\\Music\\\\Model_Deployment'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prahalad_ReddyKEY.pem\n",
      "Prahalad_ReddyKEYDownloaded.pem\n"
     ]
    }
   ],
   "source": [
    "upload_directory('creds','s3_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path='s3_download'\n",
    "s3_prefix='s3_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "for result in paginator.paginate(Bucket=bucket_name, Prefix=s3_prefix):\n",
    "    if 'Contents' in result:\n",
    "        for key in result['Contents']:\n",
    "            s3_key = key['Key']\n",
    "\n",
    "            # Build the file path\n",
    "            file_path = os.path.join(local_path, os.path.relpath(s3_key, s3_prefix))\n",
    "            \n",
    "            # Ensure parent directories exist\n",
    "            os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "            \n",
    "            # Download the file\n",
    "            s3.download_file(bucket_name, s3_key, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_objects():\n",
    "  response=s3.list_objects_v2(Bucket=bucket_name)\n",
    "  if 'Contents' in response:\n",
    "    \n",
    "    for obj in response['Contents']:\n",
    "      s3.delete_object(Bucket=bucket_name,Key=obj['Key'])\n",
    "\n",
    "delete_objects()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3=boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets=s3.list_buckets()['Buckets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'sreenu-bucket-1234',\n",
       "  'CreationDate': datetime.datetime(2024, 12, 30, 10, 32, 14, tzinfo=tzutc())},\n",
       " {'Name': 'tinybertsentimentanalysis',\n",
       "  'CreationDate': datetime.datetime(2024, 12, 30, 10, 4, 15, tzinfo=tzutc())}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets=[buckets[i]['Name'] for i in range(len(buckets))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sreenu-bucket-1234', 'tinybertsentimentanalysis']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (BucketNotEmpty) when calling the DeleteBucket operation: The bucket you tried to delete is not empty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_bucket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuckets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bored\\Music\\Model_Deployment\\awsvenv\\Lib\\site-packages\\botocore\\client.py:569\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    567\u001b[0m     )\n\u001b[0;32m    568\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bored\\Music\\Model_Deployment\\awsvenv\\Lib\\site-packages\\botocore\\client.py:1023\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1021\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m-> 1023\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mClientError\u001b[0m: An error occurred (BucketNotEmpty) when calling the DeleteBucket operation: The bucket you tried to delete is not empty"
     ]
    }
   ],
   "source": [
    "s3.delete_bucket(Bucket=buckets[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\bored\\\\Music\\\\Model_Deployment'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_folder_to_s3(local_folder, bucket_name):\n",
    "    \"\"\"\n",
    "    Uploads a local folder and its contents to an S3 bucket, maintaining the folder structure\n",
    "    and avoiding file conflicts by including the parent folder name in the S3 key.\n",
    "\n",
    "    Parameters:\n",
    "        local_folder (str): Path to the local folder to upload.\n",
    "        bucket_name (str): Name of the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize S3 client\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Get the parent folder name (e.g., \"my_folder1\" from \"C:/my_folder1\")\n",
    "    parent_folder_name = os.path.basename(local_folder)\n",
    "\n",
    "    for root, dirs, files in os.walk(local_folder):\n",
    "        for file in files:\n",
    "            # Construct full local path\n",
    "            local_file_path = os.path.join(root, file)\n",
    "\n",
    "            # Construct S3 key by including the parent folder name\n",
    "            relative_path = os.path.relpath(local_file_path, local_folder)\n",
    "            s3_key = os.path.join(parent_folder_name, relative_path).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            try:\n",
    "                # Upload file to S3\n",
    "                s3.upload_file(local_file_path, bucket_name, s3_key)\n",
    "                print(f\"Uploaded: {local_file_path} to s3://{bucket_name}/{s3_key}\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File not found: {local_file_path}\")\n",
    "            except NoCredentialsError:\n",
    "                print(\"AWS credentials not found.\")\n",
    "            except PartialCredentialsError:\n",
    "                print(\"Incomplete AWS credentials.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders_to_upload = [\"disaster_management_classification\", \"pose_classification\", \"tinybert_Downloaded\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='pose_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name='tinybertsentimentanalysis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: pose_classification\\config.json to s3://tinybertsentimentanalysis/pose_classification/config.json\n",
      "Uploaded: pose_classification\\model.safetensors to s3://tinybertsentimentanalysis/pose_classification/model.safetensors\n",
      "Uploaded: pose_classification\\preprocessor_config.json to s3://tinybertsentimentanalysis/pose_classification/preprocessor_config.json\n"
     ]
    }
   ],
   "source": [
    "upload_folder_to_s3(folder, bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'folders_to_upload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m bucket_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtinybertsentimentanalysis\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m      2\u001b[0m s3_folder_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder \u001b[38;5;129;01min\u001b[39;00m \u001b[43mfolders_to_upload\u001b[49m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading folder: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     upload_folder_to_s3(folder, bucket_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'folders_to_upload' is not defined"
     ]
    }
   ],
   "source": [
    "bucket_name = \"tinybertsentimentanalysis\" \n",
    "s3_folder_prefix = \"models/\" \n",
    "for folder in folders_to_upload:\n",
    "    print(f\"Uploading folder: {folder}\")\n",
    "    upload_folder_to_s3(folder, bucket_name)\n",
    "\n",
    "print(\"Upload complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awsvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
